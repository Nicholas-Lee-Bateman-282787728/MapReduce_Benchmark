  In mathematics, a polynomial is an expression consisting of variables (or indeterminates) and coefficients, that involves only the operations of addition, subtraction, multiplication, and non-negative integer exponents. An example of a polynomial of a single indeterminate  is . An example in three variables is . Polynomials appear in a wide variety of areas of mathematics and science. For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated problems in the sciences; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions. In advanced mathematics, polynomials are used to construct polynomial rings and algebraic varieties, central concepts in algebra and algebraic geometry. According to the Oxford English Dictionary, polynomial succeeded the term binomial, and was made simply by replacing the Latin root bi- with the Greek poly-, which comes from the Greek word for many. The word polynomial was first used in the 17th century.Etymology of "polynomial". Compact Oxford English Dictionary  The x occurring in a polynomial is commonly called either a variable or an indeterminate. When the polynomial is considered as an expression, x is a fixed symbol which does not have any value (its value is "indeterminate"). It is thus more correct to call it an "indeterminate". However, when one considers the function defined by the polynomial, then x represents the argument of the function, and is therefore called a "variable". Many authors use these two words interchangeably. It is a common convention to use uppercase letters for the indeterminates and the corresponding lowercase letters for the variables (arguments) of the associated function. It may be confusing that a polynomial P in the indeterminate x may appear in the formulas either as P or as P(x). Normally, the name of the polynomial is P, not P(x). However, if a denotes a number, a variable, another polynomial, or, more generally any expression, then P(a) denotes, by convention, the result of substituting x by a in P. For example, the polynomial P defines the function x\mapsto P(x) In particular, if a = x, then the definition of P(a) implies P=P(x). This equality allows writing "let P(x) be a polynomial" as a shorthand for "let P be a polynomial in the indeterminate x". On the other hand, when it is not necessary to emphasize the name of the indeterminate, many formulas are much simpler and easier to read if the name(s) of the indeterminate(s) do not appear at each occurrence of the polynomial. A polynomial is an expression that can be built from constants and symbols called indeterminates or variables by means of addition, multiplication and exponentiation to a non-negative power. Two such expressions that may be transformed, one to the other, by applying the usual properties of commutativity, associativity and distributivity of addition and multiplication are considered as defining the same polynomial. A polynomial in a single indeterminate x can always be written (or rewritten) in the form a_n x^n + a_{n-1}x^{n-1} + \dotsb + a_2 x^2 + a_1 x + a_0, where a_0, \ldots, a_n are constants and x is the indeterminate. The word "indeterminate" means that x does not represent any value, although any value may be substituted for it. The mapping that associates the result of this substitution to the substituted value is a function, called a polynomial function. This can be expressed more concisely by using summation notation: \sum_{i=0}^n a_i x^i That is, a polynomial can either be zero or can be written as the sum of a finite number of non-zero terms. Each term consists of the product of a number—called the coefficient of the termThe coefficient of a term may be any number from a specified set. If that set is the set of real numbers, we speak of "polynomials over the reals". Other common kinds of polynomials are polynomials with integer coefficients, polynomials with complex coefficients, and polynomials with coefficients that are integers modulo of some prime number .—and a finite number of indeterminates, raised to nonnegative integer powers. The exponent on an indeterminate in a term is called the degree of that indeterminate in that term; the degree of the term is the sum of the degrees of the indeterminates in that term, and the degree of a polynomial is the largest degree of any one term with nonzero coefficient. Because , the degree of an indeterminate without a written exponent is one. A term and a polynomial with no indeterminates are called respectively a constant term and a constant polynomial;This terminology date from the time where the distinction was not clear between a polynomial and the function that it defines: a constant term and a constant polynomial define constant functions. the degree of a constant term and of a nonzero constant polynomial is 0. The degree of the zero polynomial (which has no term) is generally treated as not defined (but see below). For example:  -5x^2y  is a term. The coefficient is , the indeterminates are  and , the degree of  is two, while the degree of  is one. The degree of the entire term is the sum of the degrees of each indeterminate in it, so in this example the degree is . Forming a sum of several terms produces a polynomial. For example, the following is a polynomial: \underbrace{_\,3x^2}_{\begin{smallmatrix}\mathrm{term}\\\mathrm{1}\end{smallmatrix}} \underbrace{-_\,5x}_{\begin{smallmatrix}\mathrm{term}\\\mathrm{2}\end{smallmatrix}} \underbrace{+_\,4}_{\begin{smallmatrix}\mathrm{term}\\\mathrm{3}\end{smallmatrix}}.  It consists of three terms: the first is degree two, the second is degree one, and the third is degree zero. Polynomials of small degree have been given specific names. A polynomial of degree zero is a constant polynomial or simply a constant. Polynomials of degree one, two or three are respectively linear polynomials, quadratic polynomials and cubic polynomials. For higher degrees the specific names are not commonly used, although quartic polynomial (for degree four) and quintic polynomial (for degree five) are sometimes used. The names for the degrees may be applied to the polynomial or to its terms. For example, in  the term  is a linear term in a quadratic polynomial. The polynomial 0, which may be considered to have no terms at all, is called the zero polynomial. Unlike other constant polynomials, its degree is not zero. Rather the degree of the zero polynomial is either left explicitly undefined, or defined as negative (either −1 or −∞). These conventions are useful when defining Euclidean division of polynomials. The zero polynomial is also unique in that it is the only polynomial having an infinite number of roots. In the case of polynomials in more than one indeterminate, a polynomial is called homogeneous of  if all its non-zero terms have . The zero polynomial is homogeneous, and, as homogeneous polynomial, its degree is undefined.In fact, as homogeneous function, it is homogeneous of every degree For example,  is homogeneous of degree 5. For more details, see homogeneous polynomial. The commutative law of addition can be used to rearrange terms into any preferred order. In polynomials with one indeterminate, the terms are usually ordered according to degree, either in "descending powers of ", with the term of largest degree first, or in "ascending powers of ". The polynomial in the example above is written in descending powers of . The first term has coefficient , indeterminate , and exponent . In the second term, the coefficient . The third term is a constant. Because the degree of a non-zero polynomial is the largest degree of any one term, this polynomial has degree two. Two terms with the same indeterminates raised to the same powers are called "similar terms" or "like terms", and they can be combined, using the distributive law, into a single term whose coefficient is the sum of the coefficients of the terms that were combined. It may happen that this makes the coefficient 0. Polynomials can be classified by the number of terms with nonzero coefficients, so that a one-term polynomial is called a monomial,Some authors use "monomial" to mean "monic monomial". See  a two-term polynomial is called a binomial, and a three-term polynomial is called a trinomial. The term "quadrinomial" is occasionally used for a four-term polynomial. A polynomial in one indeterminate is called a univariate polynomial, a polynomial in more than one indeterminate is called a multivariate polynomial. A polynomial with two indeterminates is called a bivariate polynomial. These notions refer more to the kind of polynomials one is generally working with than to individual polynomials; for instance when working with univariate polynomials one does not exclude constant polynomials (which may result, for instance, from the subtraction of non-constant polynomials), although strictly speaking constant polynomials do not contain any indeterminates at all. It is possible to further classify multivariate polynomials as bivariate, trivariate, and so on, according to the maximum number of indeterminates allowed. Again, so that the set of objects under consideration be closed under subtraction, a study of trivariate polynomials usually allows bivariate polynomials, and so on. It is common, also, to say simply "polynomials in , and ", listing the indeterminates allowed. The evaluation of a polynomial consists of substituting a numerical value to each indeterminate and carrying out the indicated multiplications and additions. For polynomials in one indeterminate, the evaluation is usually more efficient (lower number of arithmetic operations to perform) using Horner's method: (((\dotsb((a_n x + a_{n-1})x + a_{n-2})x + \dotsb + a_3)x + a_2)x + a_1)x + a_0. Polynomials can be added using the associative law of addition (grouping all their terms together into a single sum), possibly followed by reordering, and combining of like terms. For example, if \begin{align}  P &= 3x^2 - 2x + 5xy - 2 \\  Q &= -3x^2 + 3x + 4y^2 + 8 \end{align} then P + Q = 3x^2 - 2x + 5xy - 2 - 3x^2 + 3x + 4y^2 + 8  which can be simplified to P + Q = x + 5xy + 4y^2 + 6  To work out the product of two polynomials into a sum of terms, the distributive law is repeatedly applied, which results in each term of one polynomial being multiplied by every term of the other. For example, if \begin{align}  \color{Brown} P &\color{Brown}{= 2x + 3y + 5} \\  \color{RoyalBlue} Q &\color{RoyalBlue}{= 2x + 5y + xy + 1} \end{align} then \begin{array}{rccrcrcrcr} {\color{Brown}{P}} {\color{RoyalBlue}{Q}} & {{=}}&&({\color{Brown}{2x}}\cdot{\color{RoyalBlue}{2x}}) &+&({\color{Brown}{2x}}\cdot{\color{RoyalBlue}{5y}})&+&({\color{Brown}{2x}}\cdot {\color{RoyalBlue}{xy}})&+&({\color{Brown}{2x}}\cdot{\color{RoyalBlue}{1}}) \\&&+&({\color{Brown}{3y}}\cdot{\color{RoyalBlue}{2x}})&+&({\color{Brown}{3y}}\cdot{\color{RoyalBlue}{5y}})&+&({\color{Brown}{3y}}\cdot {\color{RoyalBlue}{xy}})&+& ({\color{Brown}{3y}}\cdot{\color{RoyalBlue}{1}}) \\&&+&({\color{Brown}{5}}\cdot{\color{RoyalBlue}{2x}})&+&({\color{Brown}{5}}\cdot{\color{RoyalBlue}{5y}})&+& ({\color{Brown}{5}}\cdot {\color{RoyalBlue}{xy}})&+&({\color{Brown}{5}}\cdot{\color{RoyalBlue}{1}}) \end{array} which can be simplified to PQ = 4x^2 + 21xy + 2x^2y + 12x + 15y^2 + 3xy^2 + 28y + 5 Polynomial evaluation can be used to compute the remainder of polynomial division by a polynomial of degree one, because the remainder of the division of  by  is ; see the polynomial remainder theorem. This is more efficient than the usual algorithm of division when the quotient is not needed. As for the integers, two kinds of divisions are considered for the polynomials. The Euclidean division of polynomials that generalizes the Euclidean division of the integers. It results in two polynomials, a quotient and a remainder that are characterized by the following property of the polynomials: given two polynomials a and b such that b ≠ 0, there exists a unique pair of polynomials, q, the quotient, and r, the remainder, such that  and  (here the polynomial zero is supposed to have a negative degree). By hand as well as with a computer, this division can be computed by the polynomial long division algorithm.Peter H. Selby, Steve Slavin, Practical Algebra: A Self-Teaching Guide, 2nd Edition, Wiley, ISBN 0-471-53012-3 ISBN 978-0-471-53012-1 All polynomials with coefficients in a unique factorization domain (for example, the integers or a field) also have a factored form in which the polynomial is written as a product of irreducible polynomials and a constant. This factored form is unique up to the order of the factors and their multiplication by an invertible constant. In the case of the field of complex numbers, the irreducible factors are linear. Over the real numbers, they have the degree either one or two. Over the integers and the rational numbers the irreducible factors may have any degree. For example, the factored form of  5x^3-5 is 5(x - 1)\left(x^2 + x + 1\right) over the integers and the reals and  5(x - 1)\left(x + \frac{1 + i\sqrt{3}}{2}\right)\left(x + \frac{1 - i\sqrt{3}}{2}\right) over the complex numbers. The computation of the factored form, called factorization is, in general, too difficult to be done by hand-written computation. However, efficient polynomial factorization algorithms are available in most computer algebra systems. A formal quotient of polynomials, that is, an algebraic fraction wherein the numerator and denominator are polynomials, is called a "rational expression" or "rational fraction" and is not, in general, a polynomial. Division of a polynomial by a number, however, yields another polynomial. For example,  is considered a valid term in a polynomial (and a polynomial by itself) because it is equivalent to  and  is just a constant. When this expression is used as a term, its coefficient is therefore . For similar reasons, if complex coefficients are allowed, one may have a single term like ; even though it looks like it should be expanded to two terms, the complex number  is one complex number, and is the coefficient of that term. The expression  is not a polynomial because it includes division by a non-constant polynomial. The expression  is not a polynomial, because it contains an indeterminate used as exponent. Because subtraction can be replaced by addition of the opposite quantity, and because positive integer exponents can be replaced by repeated multiplication, all polynomials can be constructed from constants and indeterminates using only addition and multiplication.  A polynomial function is a function that can be defined by evaluating a polynomial. A function  of one argument is thus a polynomial function if it satisfies.  f(x) = a_n x^n + a_{n-1} x^{n-1} + \cdots + a_2 x^2 + a_1 x + a_0 \,  for all arguments , where  is a non-negative integer and  are constant coefficients. For example, the function , taking real numbers to real numbers, defined by  f(x) = x^3 - x\, is a polynomial function of one variable. Polynomial functions of multiple variables are similarly defined, using polynomials in multiple indeterminates, as in f(x,y)= 2x^3+4x^2y+xy^5+y^2-7.\, An example is also the function f(x)=\cos(2\arccos(x)) which, although it doesn't look like a polynomial, is a polynomial function on [-1,1] because for every x from [-1,1] it is true that f(x)=2x^2-1 (see Chebyshev polynomials). Polynomial functions are a class of functions having many important properties. They are all continuous, smooth, entire, computable, etc.   File:Polynomialdeg2.svg|Polynomial of degree 2: File:Polynomialdeg3.svg|Polynomial of degree 3: File:Polynomialdeg4.svg|Polynomial of degree 4: File:quintic polynomial.svg|Polynomial of degree 5: File:Sextic Graph.svg|Polynomial of degree 6: File:Septic graph.svg|Polynomial of degree 7:   A polynomial function in one real variable can be represented by a graph. : is the -axis. :, where , is a horizontal line with  : , where , is an oblique line with  and slope . :, where  is a parabola. :, where  is a cubic curve. : , where  is a continuous non-linear curve. The graph of a non-constant (univariate) polynomial always tends to infinity when the variable increases indefinitely (in absolute value). Polynomial graphs are analyzed in calculus using intercepts, slopes, concavity, and end behavior.  A polynomial equation, also called algebraic equation, is an equation of the form a_n x^n + a_{n-1}x^{n-1} + \dotsb + a_2 x^2 + a_1 x + a_0 = 0. For example,  3x^2 + 4x -5 = 0 \, is a polynomial equation. In case of a univariate polynomial equation, the variable is considered an unknown, and one seeks to find the possible values for which both members of the equation evaluate to the same value (in general more than one solution may exist). A polynomial equation stands in contrast to a polynomial identity like , where both expressions represent the same polynomial in different forms, and as a consequence any evaluation of both members gives a valid equality. In elementary algebra, methods such as the quadratic formula are given for solving all first degree and second degree polynomial equations in one variable. There are also formulas for the cubic and quartic equations. For higher degrees, the Abel–Ruffini theorem asserts that there can not exist a general formula in radicals. However, root-finding algorithms may be used to find numerical approximations of the roots of a polynomial expression of any degree. The number of real solutions of a polynomial equation with real coefficients may not exceed the degree, and equals the degree when the complex solutions are counted with their multiplicity. This fact is called the fundamental theorem of algebra. Every polynomial  in  corresponds to a function,  (where the occurrences of  in  are interpreted as the argument of ), called the polynomial function of ; the equation in  setting  is the polynomial equation corresponding to . The solutions of this equation are called the roots of the polynomial; they are the zeroes of the function  (corresponding to the points where the graph of  meets the -axis). A number  is a root of  if and only if the polynomial  (of degree one in ) divides . It may happen that  divides  more than once: if  divides  then  is called a multiple root of , and otherwise  is called a simple root of . If  is a nonzero polynomial, there is a highest power  such that  divides , which is called the multiplicity of the root  in . When  is the zero polynomial, the corresponding polynomial equation is trivial, and this case is usually excluded when considering roots: with the above definitions every number would be a root of the zero polynomial, with undefined (or infinite) multiplicity. With this exception made, the number of roots of , even counted with their respective multiplicities, cannot exceed the degree of . The relation between the roots of a polynomial and its coefficients is described by Vieta's formulas. Some polynomials, such as , do not have any roots among the real numbers. If, however, the set of allowed candidates is expanded to the complex numbers, every non-constant polynomial has at least one root; this is the fundamental theorem of algebra. By successively dividing out factors , one sees that any polynomial with complex coefficients can be written as a constant (its leading coefficient) times a product of such polynomial factors of degree&nbsp;1; as a consequence, the number of (complex) roots counted with their multiplicities is exactly equal to the degree of the polynomial. There is a difference between approximating roots and finding exact expressions for roots. Formulas for expressing the roots of polynomials of degree 2 in terms of square roots have been known since ancient times (see quadratic equation), and for polynomials of degree 3 or 4 similar formulas (using cube roots in addition to square roots) were found in the 16th century (see cubic function and quartic function for the formulas and Niccolò Fontana Tartaglia, Lodovico Ferrari, Gerolamo Cardano, and François Viète for historical details). But formulas for degree 5 eluded researchers for several centuries. In 1824, Niels Henrik Abel proved the striking result that there can be no general (finite) formula, involving only arithmetic operations and radicals, that expresses the roots of a polynomial of degree 5 or greater in terms of its coefficients (see Abel–Ruffini theorem). In 1830, Évariste Galois, studying the permutations of the roots of a polynomial, extended the Abel–Ruffini theorem by showing that, given a polynomial equation, one may decide whether it is solvable by radicals, and, if it is, solve it. This result marked the start of Galois theory and group theory, two important branches of modern mathematics. Galois himself noted that the computations implied by his method were impracticable. Nevertheless, formulas for solvable equations of degrees 5 and 6 have been published (see quintic function and sextic equation). Numerical approximation of roots of polynomials in one unknown is easily done on a computer by the Jenkins–Traub method, Laguerre's method, Durand–Kerner method, or by some other root-finding algorithm. For polynomials in more than one indeterminate the notion of root does not exist, and there are usually infinitely many combinations of values for the variables for which the polynomial function takes the value zero. However, for certain sets of such polynomials it may happen that for only finitely many combinations all polynomial functions take the value zero. For a set of polynomial equations in several unknowns, there are algorithms to decide whether they have a finite number of complex solutions. If the number of solutions is finite, there are algorithms to compute the solutions. The methods underlying these algorithms are described in the article System of polynomial equations. The special case where all the polynomials are of degree one is called a system of linear equations, for which another range of different solution methods exist, including the classical Gaussian elimination. A polynomial equation for which one is interested only in the solutions which are integers is called a Diophantine equation. Solving Diophantine equations is a very hard task. It has been proved that there cannot be any general algorithm for solving them, and even for deciding is the set of solutions is empty (see Hilbert's tenth problem). Some of the most famous problems that has been solved during the fifty last years are related to Diophantine equations, such as Fermat's Last Theorem. There are at least two ways to generalize polynomials:  A trigonometric polynomial is a finite linear combination of functions sin(nx) and cos(nx) with n taking on the values of one or more natural numbers. The coefficients may be taken as real numbers, for real-valued functions. For complex coefficients, there is no difference between such a function and a finite Fourier series. Trigonometric polynomials are widely used, for example in trigonometric interpolation applied to the interpolation of periodic functions. They are used also in the discrete Fourier transform. The term trigonometric polynomial for the real-valued case can be seen as using the analogy: the functions sin(nx) and cos(nx) are similar to the monomial basis for polynomials. In the complex case the trigonometric polynomials are spanned by the positive and negative powers of eix.  A matrix polynomial is a polynomial with matrices as variables. Given an ordinary, scalar-valued polynomial P(x) = \sum_{i=0}^n{ a_i x^i} =a_0 + a_1 x+ a_2 x^2 + \cdots + a_n x^n,  this polynomial evaluated at a matrix A is P(A) = \sum_{i=0}^n{ a_i A^i} =a_0 I + a_1 A + a_2 A^2 + \cdots + a_n A^n, where I is the identity matrix. A matrix polynomial equation is an equality between two matrix polynomials, which holds for the specific matrices in question. A matrix polynomial identity is a matrix polynomial equation which holds for all matrices A in a specified matrix ring Mn(R).  Laurent polynomials are like polynomials, but allow negative powers of the variable(s) to occur.  A rational fraction is the quotient (algebraic fraction) of two polynomials. Any algebraic expression that can be rewritten as a rational fraction is a rational function. While polynomial functions are defined for all values of the variables, a rational function is defined only for the values of the variables for which the denominator is not zero. The rational fractions include the Laurent polynomials, but do not limit denominators to powers of an indeterminate.  Formal power series are like polynomials, but allow infinitely many non-zero terms to occur, so that they do not have finite degree. Unlike polynomials they cannot in general be explicitly and fully written down (just like real numbers cannot), but the rules for manipulating their terms are the same as for polynomials. Non-formal power series also generalize polynomials, but the multiplication of two power series may not converge.   The simple structure of polynomial functions makes them quite useful in analyzing general functions using polynomial approximations. An important example in calculus is Taylor's theorem, which roughly states that every differentiable function locally looks like a polynomial function, and the Stone–Weierstrass theorem, which states that every continuous function defined on a compact interval of the real axis can be approximated on the whole interval as closely as desired by a polynomial function. Calculating derivatives and integrals of polynomial functions is particularly simple. For the polynomial function \sum_{i=0}^n a_i x^i the derivative with respect to x is \sum_{i=1}^n a_i i x^{i-1} and the indefinite integral is \sum_{i=0}^n {a_i\over i+1} x^{i+1}+c.  In abstract algebra, one distinguishes between polynomials and polynomial functions. A polynomial  in one indeterminate  over a ring  is defined as a formal expression of the form f = a_n x^n + a_{n - 1} x^{n - 1} + \cdots + a_1 x^1 + a_0x^0 where  is a natural number, the coefficients  are elements of , and  is a formal symbol, whose powers  are just placeholders for the corresponding coefficients , so that the given formal expression is just a way to encode the sequence , where there is an  such that  for all . Two polynomials sharing the same value of n are considered equal if and only if the sequences of their coefficients are equal; furthermore any polynomial is equal to any polynomial with greater value of  obtained from it by adding terms in front whose coefficient is zero. These polynomials can be added by simply adding corresponding coefficients (the rule for extending by terms with zero coefficients can be used to make sure such coefficients exist). Thus each polynomial is actually equal to the sum of the terms used in its formal expression, if such a term  is interpreted as a polynomial that has zero coefficients at all powers of  other than . Then to define multiplication, it suffices by the distributive law to describe the product of any two such terms, which is given by the rule a x^k \; b x^l = ab x^{k+l} for all elements a, b of the ring R and all natural numbers k and l. Thus the set of all polynomials with coefficients in the ring  forms itself a ring, the ring of polynomials over , which is denoted by . The map from  to  sending  to  is an injective homomorphism of rings, by which  is viewed as a subring of . If  is commutative, then  is an algebra over . One can think of the ring  as arising from  by adding one new element x to R, and extending in a minimal way to a ring in which  satisfies no other relations than the obligatory ones, plus commutation with all elements of  (that is ). To do this, one must add all powers of  and their linear combinations as well. Formation of the polynomial ring, together with forming factor rings by factoring out ideals, are important tools for constructing new rings out of known ones. For instance, the ring (in fact field) of complex numbers, which can be constructed from the polynomial ring  over the real numbers by factoring out the ideal of multiples of the polynomial . Another example is the construction of finite fields, which proceeds similarly, starting out with the field of integers modulo some prime number as the coefficient ring  (see modular arithmetic). If  is commutative, then one can associate to every polynomial  in , a polynomial function  with domain and range equal to  (more generally one can take domain and range to be the same unital associative algebra over ). One obtains the value  by substitution of the value  for the symbol  in . One reason to distinguish between polynomials and polynomial functions is that over some rings different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where  is the integers modulo ). This is not the case when  is the real or complex numbers, whence the two concepts are not always distinguished in analysis. An even more important reason to distinguish between polynomials and polynomial functions is that many operations on polynomials (like Euclidean division) require looking at what a polynomial is composed of as an expression rather than evaluating it at some constant value for .  In commutative algebra, one major focus of study is divisibility among polynomials. If  is an integral domain and  and  are polynomials in , it is said that  divides  or  is a divisor of  if there exists a polynomial  in  such that . One can show that every zero gives rise to a linear divisor, or more formally, if  is a polynomial in  and  is an element of  such that , then the polynomial () divides . The converse is also true. The quotient can be computed using the polynomial long division. If  is a field and  and  are polynomials in  with , then there exist unique polynomials  and  in  with  f = q \, g + r  and such that the degree of  is smaller than the degree of  (using the convention that the polynomial 0 has a negative degree). The polynomials  and  are uniquely determined by  and . This is called Euclidean division, division with remainder or polynomial long division and shows that the ring  is a Euclidean domain. Analogously, prime polynomials (more correctly, irreducible polynomials) can be defined as non-zero polynomials which cannot be factorized into the product of two non constant polynomials. In the case of coefficients in a ring, "non constant" must be replaced by "non constant or non unit" (both definitions agree in the case of coefficients in a field). Any polynomial may be decomposed into the product of an invertible constant by a product of irreducible polynomials. If the coefficients belong to a field or a unique factorization domain this decomposition is unique up to the order of the factors and the multiplication of any non unit factor by a unit (and division of the unit factor by the same unit). When the coefficients belong to integers, rational numbers or a finite field, there are algorithms to test irreducibility and to compute the factorization into irreducible polynomials (see Factorization of polynomials). These algorithms are not practicable for hand written computation, but are available in any computer algebra system. Eisenstein's criterion can also be used in some cases to determine irreducibility.  Polynomials serve to approximate other functions, such as the use of splines. Polynomials are frequently used to encode information about some other object. The characteristic polynomial of a matrix or linear operator contains information about the operator's eigenvalues. The minimal polynomial of an algebraic element records the simplest algebraic relation satisfied by that element. The chromatic polynomial of a graph counts the number of proper colourings of that graph. The term "polynomial", as an adjective, can also be used for quantities or functions that can be written in polynomial form. For example, in computational complexity theory the phrase polynomial time means that the time it takes to complete an algorithm is bounded by a polynomial function of some variable, such as the size of the input.  Determining the roots of polynomials, or "solving algebraic equations", is among the oldest problems in mathematics. However, the elegant and practical notation we use today only developed beginning in the 15th century. Before that, equations were written out in words. For example, an algebra problem from the Chinese Arithmetic in Nine Sections, circa 200 BCE, begins "Three sheafs of good crop, two sheafs of mediocre crop, and one sheaf of bad crop are sold for 29 dou." We would write .  The earliest known use of the equal sign is in Robert Recorde's The Whetstone of Witte, 1557. The signs + for addition, − for subtraction, and the use of a letter for an unknown appear in Michael Stifel's Arithemetica integra, 1544. René Descartes, in La géometrie, 1637, introduced the concept of the graph of a polynomial equation. He popularized the use of letters from the beginning of the alphabet to denote constants and letters from the end of the alphabet to denote variables, as can be seen above, in the general formula for a polynomial in one variable, where the 's denote constants and  denotes a variable. Descartes introduced the use of superscripts to denote exponents as well.Howard Eves, An Introduction to the History of Mathematics, Sixth Edition, Saunders, ISBN 0-03-029558-0   A sum of polynomials is a polynomial. A product of polynomials is a polynomial. A composition of two polynomials is a polynomial, which is obtained by substituting a variable of the first polynomial by the second polynomial. The derivative of the polynomial  is the polynomial . If the set of the coefficients does not contain the integers (for example if the coefficients are integers modulo some prime number ), then  should be interpreted as the sum of  with itself,  times. For example, over the integers modulo , the derivative of the polynomial  is the polynomial . A primitive integral or antiderivative of the polynomial  is the polynomial , where  is an arbitrary constant. For instance, the antiderivatives of  have the form . The graph of the zero polynomial The graph of a degree 0 polynomial The graph of a degree 1 polynomial (or linear function) The graph of a degree 2 polynomial The graph of a degree 3 polynomial The graph of any polynomial with degree 2 or greater The terms polynomial and polynomial expression are frequently used to denote similar objects which are obtained by summing products of functions, matrices, or other mathematical objects. Rational functions and power series include polynomials as a subset. A bivariate polynomial where the second variable is substituted by an exponential function applied to the first variable, for example , may be called an exponential polynomial. Lill's method List of polynomial topics Polynomials on vector spaces Power series Table of mathematical expressions Polynomial transformations . This classical book covers most of the content of this article. Mayr, K. Über die Auflösung algebraischer Gleichungssysteme durch hypergeometrische Funktionen. Monatshefte für Mathematik und Physik vol. 45, (1937) pp.&nbsp;280–313. Umemura, H. Solution of algebraic equations in terms of theta constants. In D. Mumford, Tata Lectures on Theta II, Progress in Mathematics 43, Birkhäuser, Boston, 1984. von Lindemann, F. Über die Auflösung der algebraischen Gleichungen durch transcendente Functionen. Nachrichten von der Königl. Gesellschaft der Wissenschaften, vol. 7, 1884. Polynomial solutions in terms of theta functions. von Lindemann, F. Über die Auflösung der algebraischen Gleichungen durch transcendente Functionen II. Nachrichten von der Königl. Gesellschaft der Wissenschaften und der Georg-Augusts-Universität zu Göttingen, 1892 edition.
